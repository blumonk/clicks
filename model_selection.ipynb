{
 "metadata": {
  "name": "",
  "signature": "sha256:0381aca037bda3816b83fcfa0c2106bd006f1ee4ae58791cc2f1e3de3ebf9653"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Data preparation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run 'prepare.py'\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Drop all big categorical features, use one-hot encoding on small categorical features, scale features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "from sklearn.preprocessing import scale\n",
      "\n",
      "to_drop = ['id', 'iata_from', 'iata_to', 'referer', 'iso_from', 'iso_to', 'ak_from', 'ak_to', 'combo_type']\n",
      "to_convert = ['flight_class', 'combo', 'mobile']\n",
      "to_scale = ['date', 'price', 'total_price', 'a_days', 'days', 'date_from', 'date_back']\n",
      "\n",
      "prepared = clicks.drop(to_drop, axis=1)\n",
      "prepared = prepared[prepared.total_price < 2000000]\n",
      "\n",
      "for feature in to_convert:\n",
      "    dummies = pd.get_dummies(prepared[feature], prefix=feature)\n",
      "    prepared = pd.concat([prepared.drop(feature, axis=1), dummies], axis=1)\n",
      "\n",
      "for feature in to_scale:\n",
      "    prepared[feature] = scale(prepared[feature])\n",
      "\n",
      "prepared.head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>return</th>\n",
        "      <th>date</th>\n",
        "      <th>adt</th>\n",
        "      <th>chd</th>\n",
        "      <th>inf</th>\n",
        "      <th>price</th>\n",
        "      <th>total_price</th>\n",
        "      <th>a_days</th>\n",
        "      <th>days</th>\n",
        "      <th>date_from</th>\n",
        "      <th>date_back</th>\n",
        "      <th>book</th>\n",
        "      <th>pr_to</th>\n",
        "      <th>pr_back</th>\n",
        "      <th>flight_class_B</th>\n",
        "      <th>flight_class_E</th>\n",
        "      <th>combo_0</th>\n",
        "      <th>combo_1</th>\n",
        "      <th>mobile_0</th>\n",
        "      <th>mobile_1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>1.744608</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>-0.521755</td>\n",
        "      <td>-0.149794</td>\n",
        "      <td>0.072214</td>\n",
        "      <td>-0.121384</td>\n",
        "      <td>1.511502</td>\n",
        "      <td>1.422976</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>0</td>\n",
        "      <td>1.744608</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>-0.498217</td>\n",
        "      <td>-0.699748</td>\n",
        "      <td>-0.737759</td>\n",
        "      <td>-0.813059</td>\n",
        "      <td>0.963666</td>\n",
        "      <td>0.712106</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>0</td>\n",
        "      <td>1.744608</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>-0.273350</td>\n",
        "      <td>-0.561361</td>\n",
        "      <td>-0.596894</td>\n",
        "      <td>-0.813059</td>\n",
        "      <td>1.058942</td>\n",
        "      <td>0.803831</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "   return      date  adt  chd  inf     price  total_price    a_days      days  \\\n",
        "0       1  1.744608    2    1    0 -0.521755    -0.149794  0.072214 -0.121384   \n",
        "1       0  1.744608    1    0    0 -0.498217    -0.699748 -0.737759 -0.813059   \n",
        "2       0  1.744608    1    0    1 -0.273350    -0.561361 -0.596894 -0.813059   \n",
        "\n",
        "   date_from  date_back  book  pr_to  pr_back  flight_class_B  flight_class_E  \\\n",
        "0   1.511502   1.422976     0      2        2               0               1   \n",
        "1   0.963666   0.712106     0      1        0               0               1   \n",
        "2   1.058942   0.803831     0      1        0               0               1   \n",
        "\n",
        "   combo_0  combo_1  mobile_0  mobile_1  \n",
        "0        1        0         0         1  \n",
        "1        1        0         0         1  \n",
        "2        1        0         1         0  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Model selection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_selection import SelectPercentile, f_classif\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "data, target = prepared.drop('book', axis=1), prepared.book\n",
      "data = SelectPercentile(f_classif, percentile=60).fit_transform(data, target)\n",
      "\n",
      "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.4)\n",
      "dataset = (x_train, x_test, y_train, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "\n",
      "def log_loss(algo, x_train, x_test, y_train, y_test):    \n",
      "    algo.fit(x_train, y_train)\n",
      "    test_probs = algo.predict_proba(x_test)[:,1]\n",
      "    return type(algo).__name__, metrics.log_loss(y_test, test_probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.dummy import DummyClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.ensemble import BaggingClassifier\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.gaussian_process import GaussianProcessClassifier\n",
      "from sklearn.mixture import BayesianGaussianMixture\n",
      "\n",
      "classifiers = [\n",
      "    DummyClassifier(strategy='prior'),\n",
      "    LogisticRegression(),\n",
      "    GaussianNB(),    \n",
      "    DecisionTreeClassifier(max_depth=10),\n",
      "    RandomForestClassifier(max_depth=10),\n",
      "    MLPClassifier(alpha=1),\n",
      "    SGDClassifier(loss='log'),\n",
      "    QuadraticDiscriminantAnalysis(),\n",
      "    BaggingClassifier(),\n",
      "    AdaBoostClassifier(),\n",
      "    GradientBoostingClassifier(max_depth=10),\n",
      "]\n",
      "\n",
      "for c in classifiers:\n",
      "    print(\"{0}: {%.3f}\".format(*log_loss(c, *dataset)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('DummyClassifier', 0.25209490261731671)\n",
        "('LogisticRegression', 0.24695391293179544)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('GaussianNB', 0.30120673145977228)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('DecisionTreeClassifier', 0.26831775152774079)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('RandomForestClassifier', 0.24576184121187944)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('MLPClassifier', 0.24772153159650351)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('SGDClassifier', 0.24944806336564054)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('QuadraticDiscriminantAnalysis', 2.4520587931521236)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('BaggingClassifier', 1.4124712997076325)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('AdaBoostClassifier', 0.66996781281577722)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('GradientBoostingClassifier', 0.24773202872223182)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/blumonk/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:694: UserWarning: Variables are collinear\n",
        "  warnings.warn(\"Variables are collinear\")\n"
       ]
      }
     ],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}